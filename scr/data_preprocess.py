from datetime import timedelta
import pandas as pd
import datetime
import os 
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
# æ—¥æœ¬èªå¯¾å¿œ
import japanize_matplotlib

import import_weatherdata as wd
import import_diseasedata as dd

def preprocess_data(
        disease_df, 
        weather_df, 
        period_order, 
        use_past_incidence=False, 
        output_dir="results_it",
        test_years=None
    ):
    """
    å‰å‡¦ç†æ®µéšã§å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
    """
    print("---------------------------------------------------")
    print("ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    

    if use_past_incidence:
        disease_df = dd.add_incidence_cumsum(disease_df, period_order)
        disease_df = dd.add_all_incidence_diffs(disease_df, period_order)
    merged_df = merge_disease_and_weather(disease_df, weather_df, period_order, use_past_incidence)
    cleaned_df = drop_missing_records(merged_df)
    log_df = log_transform_target(cleaned_df, target_col="incidence", log_offset=1, new_col="log_incidence")
    if use_past_incidence:
        log_df = dd.add_past_period_log_actuals(log_df, period_order)

    cleaned_log_df = detect_and_remove_outliers(log_df, period_order=period_order, target_col="log_incidence", output_dir="results_it/log_outlier")
    stepwise_data = pivot_by_period(cleaned_log_df, period_order)

    # å­¦ç¿’ç”¨ãƒ»ãƒ†ã‚¹ãƒˆç”¨ã«åˆ†å‰²
    if test_years is not None:
        print(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¾ã™ã€‚ãƒ†ã‚¹ãƒˆå¹´: {test_years}")
        train_df = stepwise_data[~stepwise_data["year"].isin(test_years)].reset_index(drop=True)
        test_df  = stepwise_data[stepwise_data["year"].isin(test_years)].reset_index(drop=True)

        # ä¿å­˜å‡¦ç†
        save_merged_data_to_excel(stepwise_data, f"{output_dir}/merged_features.xlsx")
        print(f"âœ… å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {train_df.shape}, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_df.shape}")

        return train_df, test_df
    
    else:
        print("ãƒ†ã‚¹ãƒˆå¹´ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ç”¨ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")
        save_merged_data_to_excel(stepwise_data, f"{output_dir}/merged_features.xlsx")
        return stepwise_data
    

def merge_disease_and_weather(disease_df, weather_df, period_order, use_past_incidence=False):
    """
    Merge disease incidence data with weather features (average and sum)
    and add cumulative incidence and period-to-period difference columns.

    """
    print("---------------------------------------------------")
    print("ç—…å®³ãƒ‡ãƒ¼ã‚¿ã¨æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ã‚’é–‹å§‹ã—ã¾ã™ã€‚")


    # æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸
    all_records = []

    for _, row in disease_df.iterrows():
        year = row["year"]
        obs_date = row["date"]
        period = row["period"]
        record = row.to_dict()

        if obs_date is None or period is None:
            print(f"Skipped: year={year}, period={period}, obs_date={obs_date}")
            continue

        # å¹³å‡å€¤
        weather_windows_avg = wd.get_multiple_weather_period(weather_df, year, obs_date, period)
        for period_key, avg_df in weather_windows_avg.items():
            for _, feat_row in avg_df.iterrows():
                item = feat_row["weather_item"]
                val = feat_row["value"]
                col_name = f"{item}_{period_key}"
                record[col_name] = val

        # ç©ç®—å€¤ï¼ˆsumï¼‰
        weather_windows_sum = wd.get_multiple_weather_sum_period(weather_df, year, obs_date, period)
        for period_key, sum_df in weather_windows_sum.items():
            for _, feat_row in sum_df.iterrows():
                item = feat_row["weather_item"]
                val = feat_row["value"]
                col_name = f"{item}_{period_key}"
                record[col_name] = val

        all_records.append(record)

    merged_df = pd.DataFrame(all_records)

    print("ç—…å®³ãƒ‡ãƒ¼ã‚¿ã¨æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    print("---------------------------------------------------")
    return merged_df

def drop_missing_records(df):
    """
    Display and remove rows with missing values in key columns.

    Parameters
    ----------
    df : pd.DataFrame
        Merged DataFrame containing disease and weather features

    Returns
    -------
    pd.DataFrame
        Cleaned DataFrame with rows containing missing values removed
    """
    print("---------------------------------------------------")
    print("æ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’ç¢ºèªã—ã€é™¤å¤–ã—ã¾ã™ã€‚")
    
    # æ¬ æã‚’ç¢ºèªã™ã‚‹å¯¾è±¡ã®é‡è¦åˆ—
    key_columns = [
        "brand", "year", "period", "date", "incidence",
    ]

    # æ¬ æã‚’å«ã‚€è¡Œã‚’æŠ½å‡º
    missing_df = df[df[key_columns].isnull().any(axis=1)]

    # æ¬ æãŒã‚ã‚‹è¡Œã‚’è¡¨ç¤º
    if not missing_df.empty:
        print("âš ï¸ ä»¥ä¸‹ã®è¡Œã«æ¬ æãŒã‚ã‚Šã¾ã™ï¼ˆé™¤å¤–ã•ã‚Œã¾ã™ï¼‰:")
        print(missing_df[["brand", "year", "period", "date", "incidence"]])
    else:
        print("âœ… æ¬ æå€¤ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    # æ¬ æã‚’é™¤å»ã—ãŸ DataFrame ã‚’è¿”ã™
    cleaned_df = df.dropna(subset=key_columns).reset_index(drop=True)

    print("---------------------------------------------------")

    return cleaned_df

def log_transform_target(df, target_col="incidence", log_offset=1, new_col="log_incidence"):
    """
    ç›®çš„å¤‰æ•°ã‚’ log(x + offset) ã§å¤‰æ›ã—ã€æ–°ãŸãªã‚«ãƒ©ãƒ ã§è¿”ã™

    """
    df = df.copy()
    df[new_col] = np.log(df[target_col] + log_offset)
    return df

def detect_and_remove_outliers(
    df, 
    period_order,
    target_col="log_incidence", 
    output_dir="results_it/log_outlier"
):
    """
    logå¤‰æ›æ¸ˆã¿ã‚«ãƒ©ãƒ ã«å¯¾å¿œã—ã€period_orderé †ã§ãƒ«ãƒ¼ãƒ—
      - å„periodã”ã¨ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
      - å„periodã”ã¨ç®±ã²ã’å›³
      - logå¤‰æ›ï¼‹IQRæ³•ï¼ˆä¸Šå´ã®ã¿ï¼‰ã§å¤–ã‚Œå€¤æ¤œå‡ºãƒ»é™¤å»

    Parameters
    ----------
    df : pd.DataFrame
    period_order : list
        periodã®é †åºãƒªã‚¹ãƒˆ
    target_col : str
        å¯¾è±¡ã‚«ãƒ©ãƒ åï¼ˆlogå¤‰æ›æ¸ˆã¿ã‚«ãƒ©ãƒ ç­‰ï¼‰
    by : str
        periodã‚«ãƒ©ãƒ å
    output_dir : str
        ã‚°ãƒ©ãƒ•ä¿å­˜å…ˆ

    Returns
    -------
    pd.DataFrame
        å¤–ã‚Œå€¤é™¤å»æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    """
    import os
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns

    os.makedirs(output_dir, exist_ok=True)
    cleaned_df = df.copy()
    outlier_years = set()

    # period_orderé †ã«ãƒ«ãƒ¼ãƒ—
    for period in period_order:
        sub = df[df["period"] == period]
        if sub.empty:
            continue

        # 1. ç®±ã²ã’å›³ï¼ˆç¸¦å‘ããƒ»ãƒ•ã‚©ãƒ³ãƒˆå¤§ãã‚ãƒ»è«–æ–‡ã‚µã‚¤ã‚ºï¼‰
        plt.figure(figsize=(2.8, 4.2))  # æ¨ªå¹…2.8cm, ç¸¦4.2cmï¼ˆ1ã‚¤ãƒ³ãƒ=2.54cmã«æ›ç®—å¯ï¼‰
        sns.boxplot(y=target_col, data=sub, color="lightblue", width=0.5)
        plt.title(f"{period}", fontsize=18)
        plt.ylabel(target_col, fontsize=18)
        plt.xlabel("")  # xè»¸ãƒ©ãƒ™ãƒ«æ¶ˆã™ï¼ˆç¸¦å‘ããªã®ã§ä¸è¦ï¼‰
        plt.xticks(fontsize=14)
        plt.yticks(fontsize=14)
        plt.tight_layout(pad=0.2)
        plt.savefig(os.path.join(output_dir, f"{period}_boxplot.pdf"), dpi=300, bbox_inches='tight')
        plt.close()


        """ # 2. ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        plt.figure(figsize=(8,4))
        sns.histplot(sub[target_col].dropna(), bins=10, kde=True, color="green")
        plt.title(f"Histogram: {target_col} ({period})")
        plt.xlabel(target_col)
        plt.ylabel("Count")
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f"{period}_histogram.png"))
        plt.close() """

        # 3. IQRæ³•ï¼ˆä¸Šå´ã®ã¿ï¼‰
        vals = sub[target_col].dropna()
        if len(vals) < 2:  # åˆ†å¸ƒãŒååˆ†ã§ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            print(f"[{period}] ãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³ã§å¤–ã‚Œå€¤åˆ¤å®šã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
            continue
        q1 = np.percentile(vals, 25)
        q3 = np.percentile(vals, 75)
        iqr = q3 - q1
        upper = q3 + 1.5 * iqr
        outlier_mask = (sub[target_col] > upper)
        outliers = sub[outlier_mask]

        if not outliers.empty:
            print(f"[{period}] log-IQRå¤–ã‚Œå€¤ã¨ã—ã¦é™¤å¤–ã™ã‚‹å¹´åº¦:")
            for _, row in outliers.iterrows():
                print(f"  year={row['year']} (brand={row['brand']}, {target_col}={row[target_col]:.3g})")
                outlier_years.add((row['year'], row['brand'], period))
        else:
            print(f"[{period}] å¤–ã‚Œå€¤ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        # 4. å¤–ã‚Œå€¤ã‚’é™¤å»
        for _, row in outliers.iterrows():
            mask = (
                (cleaned_df["year"] == row["year"]) &
                (cleaned_df["brand"] == row["brand"]) &
                (cleaned_df["period"] == period)
            )
            cleaned_df = cleaned_df[~mask]

    print(f"===> å¤–ã‚Œå€¤é™¤å¤–å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {cleaned_df.shape}")
    return cleaned_df

def pivot_by_period(df, period_order):
    print("---------------------------------------------------")
    print("ğŸ”§ pivot_by_period(): æ•´å½¢ï¼‹NaNåˆ—é™¤å»å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")

    df = df.copy()
    # periodã‚’ã‚«ãƒ†ã‚´ãƒªå‹ã«ã—ã¦é †åºã‚’æ˜ç¤º
    df["period"] = pd.Categorical(df["period"], categories=period_order, ordered=True)
    # ãƒ–ãƒ©ãƒ³ãƒ‰â†’period_orderâ†’yearã®é †ã§ä¸¦ã¹ã‚‹
    df = df.sort_values(["brand", "period", "year"]).reset_index(drop=True)

    na_cols = df.columns[df.isna().all()].tolist()
    cleaned_df = df.drop(columns=na_cols)

    print(f"âœ… å®Œæˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {cleaned_df.shape}")
    if na_cols:
        print("ğŸ§¹ ä»¥ä¸‹ã®åˆ—ã¯å…¨è¡ŒNaNã®ãŸã‚å‰Šé™¤ã•ã‚Œã¾ã—ãŸ:")
        for col in na_cols:
            print(f"  - {col}")
    else:
        print("âœ… å…¨ã¦ã®åˆ—ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¦ã„ã¾ã™ã€‚")
    print("---------------------------------------------------")
    return cleaned_df

def save_merged_data_to_excel(df, output_path):
    """
    Save the merged disease and weather DataFrame to an Excel file.

    Parameters
    ----------
    df : pd.DataFrame
        The merged DataFrame from merge_disease_and_weather
    output_path : str
        File path to save the Excel file (e.g., 'results_it/merged_features.xlsx')
    """
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df.to_excel(output_path, index=False)
    print(f"âœ… Merged data saved to: {output_path}")


if __name__ == "__main__":
    # è¦³æ¸¬æ—¥ã‚’æŒ‡å®š
    wd_file_path = "resources/meteorological_data/1990_2025_sumoto.xlsx"
    dd_file_path = "resources/disease_data/onion_disease_sammary.xlsx"
    
    output_dir = "results_it"
    target_name = "ã‚¿ãƒ¼ã‚¶ãƒ³"
    start_year = 1994
    end_year  = 2023

    period_order = [
        "2æœˆä¸Šæ—¬", "2æœˆä¸‹æ—¬", "3æœˆä¸Šæ—¬", "3æœˆä¸‹æ—¬", "4æœˆä¸Šæ—¬", "4æœˆä¸‹æ—¬", "5æœˆä¸Šæ—¬", "5æœˆä¸‹æ—¬", "åç©«æ—¥", "è²¯è”µèª¿æŸ»"
    ]

    # ç—…å®³ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    disease_list= dd.import_disease_data(dd_file_path, target_name, start_year, end_year)
    disease_df = pd.DataFrame(disease_list)

    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
    weather_df = wd.extract_meteorological_data(wd_file_path, start_year, end_year)
    # ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸
    merged_data = preprocess_data(disease_df, weather_df, period_order)
    print(merged_data)
    

